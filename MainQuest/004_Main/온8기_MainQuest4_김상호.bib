\documentclass[12pt,a4paper]{article}

\usepackage{kotex} 

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=2.5cm,right=2.5cm,marginparwidth=1.75cm]{geometry}

%----------- APA style references & citations (starting) ---
% Useful packages
%\usepackage[natbibapa]{apacite} % APA-style citations.

\usepackage[style=apa, backend=biber]{biblatex} % APA 7th edition style citations using biblatex
\addbibresource{references.bib} % Your .bib file

% Formatting DOI in APA-7 style
%\renewcommand{\doiprefix}{https://doi.org/}

% Add additional APA 7th edition requirements
\DeclareLanguageMapping{british}{british-apa} % Set language mapping
\DeclareFieldFormat[article]{volume}{\apanum{#1}} % Format volume number

% Modify 'and' to '&' in the bibliography
\renewcommand*{\finalnamedelim}{%
  \ifnumgreater{\value{liststop}}{2}{\finalandcomma}{}%
  \addspace\&\space}
  
%----------- APA style references & citations (ending) ---


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{hyperref}
%\usepackage{orcidlink}
\usepackage[title]{appendix}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{booktabs} % For \toprule, \midrule, \botrule
\usepackage{caption}  % For \caption
\usepackage{threeparttable} % For table footnotes
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{chngcntr}
\usepackage{booktabs}
\usepackage{lipsum}
\usepackage{subcaption}
\usepackage{authblk}
\usepackage[T1]{fontenc}    % Font encoding
\usepackage{csquotes}       % Include csquotes
\usepackage{diagbox}


% Customize line spacing
\usepackage{setspace}
\onehalfspacing % 1.5 line spacing

% Redefine section and subsection numbering format
\usepackage{titlesec}
\titleformat{\section} % Redefine section numbering format
  {\normalfont\Large\bfseries}{\thesection.}{1em}{}
  
% Customize line numbering format to right-align line numbers
\usepackage{lineno} % Add the lineno package
\renewcommand\linenumberfont{\normalfont\scriptsize\sffamily\color{blue}}
\rightlinenumbers % Right-align line numbers

\linenumbers % Enable line numbering

% Define a new command for the fourth-level title.
\newcommand{\subsubsubsection}[1]{%
  \vspace{\baselineskip}% Add some space
  \noindent\textbf{#1\\}\quad% Adjust formatting as needed
}
% Change the position of the table caption above the table
\usepackage{float}   % for customizing caption position
\usepackage{caption} % for customizing caption format
\captionsetup[table]{position=top} % caption position for tables

% Define the unnumbered list
\makeatletter
\newenvironment{unlist}{%
  \begin{list}{}{%
    \setlength{\labelwidth}{0pt}%
    \setlength{\labelsep}{0pt}%
    \setlength{\leftmargin}{2em}%
    \setlength{\itemindent}{-2em}%
    \setlength{\topsep}{\medskipamount}%
    \setlength{\itemsep}{3pt}%
  }%
}{%
  \end{list}%
}
\makeatother

% Suppress the warning about \@parboxrestore
\pdfsuppresswarningpagegroup=1







%-------------------------------------------
% Paper Head
%-------------------------------------------
\title{Image Augmentation}

\author[1]{Sangho Kim}
\author[2]{Guikun Chen}


\affil[1]{\small University of California, Davis}
\affil[2]{Microsoft Research}


\date{}  % Remove date

\begin{document}
\maketitle

\begin{abstract}
최근 몇 년 동안 데이터 증강 기술은 CNN(컨볼루션 신경망)의 성능과 일반화 기능을 향상시키는 데 중추적인 역할을 했습니다. 이 문서에서는 Mixup, Cutout 및 Cutmix의 세 가지 고급 증강 방법을 살펴봅니다. 이미지 쌍과 해당 레이블 사이를 보간하여 새로운 훈련 샘플을 생성하는 Mixup은 적대적인 예제에 대한 견고성을 향상시키고 일반화를 향상시킵니다. 컷아웃은 학습 중에 이미지의 임의의 사각형 영역을 마스크하여 모델이 덜 가려진 부분에 집중하도록 하여 특성 학습을 향상시킵니다. Cutmix는 한 이미지에서 패치를 잘라서 다른 이미지에 붙여넣고 레이블을 비례적으로 혼합함으로써 Mixup과 Cutout의 장점을 결합합니다. 이 방법은 다양한 훈련 사례를 제공할 뿐만 아니라 지역 정보를 보존합니다. 다양한 데이터 세트에 대한 광범위한 실험을 통해 이러한 기술이 모델 성능과 견고성을 크게 향상한다는 것을 보여줍니다. 우리의 연구 결과는 이러한 증강 전략을 통합하면 다양한 이미지 분류 작업을 위한 보다 강력하고 일반화 가능한 모델로 이어질 수 있음을 시사합니다.

%\lipsum[1]
\end{abstract}



%-------------------------------------------
% Paper Body
%-------------------------------------------



%--- Section ---%
\section{Introduction}

최근 몇 년 동안 데이터 증강은 다양한 이미지 기반 작업에 대한 CNN(컨볼루션 신경망)의 성능을 향상시키는 데 중요한 기술이 되었습니다. 뒤집기(flipping), 회전(rotating), 자르기(cropping)와 같은 전통적인 확대 방법이 널리 사용되었지만 Mixup, Cutmix 및 Cutout과 같은 고급 기술은 모델 일반화 및 견고성이 크게 향상되었습니다.

Zhang 등이 소개한 혼합. (2018)은 두 개의 무작위 이미지와 해당 라벨의 선형 보간을 통해 가상 훈련 예제를 생성합니다. 이 방법은 훈련 예제 간에 선형적으로 동작하도록 장려하여 신경망을 정규화함으로써 과적합을 줄이고 일반화를 향상시킵니다.

DeVries와 Taylor(2017)가 제안한 컷아웃에는 훈련 중에 입력 이미지의 정사각형 영역을 마스크하는 작업이 포함됩니다. 이 기술은 모델이 이미지에서 덜 가려진 부분에 집중하도록 하여 가려져도 변하지 않는 보다 강력한 특징을 학습하는 능력을 향상시킵니다.

Yun 등이 소개한 Cutmix. (2019)는 Mixup과 Cutout의 아이디어를 결합합니다. Cutmix에서는 한 이미지의 패치를 잘라내어 다른 이미지에 붙여넣고 레이블은 패치 영역에 비례하여 혼합됩니다. 이 방법은 다양한 학습 예제를 제공하여 모델의 일반화 능력을 향상시킬 뿐만 아니라 이미지 내 로컬 정보를 유지합니다.

이러한 고급 증강 기술은 널리 채택되었으며 다양한 이미지 분류 작업에서 상당한 개선을 보여주었습니다. 다음 섹션에서는 모델 성능 향상에 있어 Mixup, Cutout 및 Cutmix의 효율성을 보여주는 방법론과 경험적 결과를 자세히 살펴보겠습니다.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{image.PNG}
  \caption{기법 예시}
  \label{fig:label}
\end{figure}




%--- Section ---%
\section{Method}\label{sec2}


본 연구에서는 Mixup, Cutmix, Cutout의 세 가지 고급 데이터 증강 기법을 사용합니다. 각각의 방법은 다양한 훈련 샘플을 생성함으로써 합성곱 신경망(CNN)의 강인성과 일반화 능력을 향상시키는 데 중점을 둡니다.

\subsection{Mixup}
Mixup은 Zhang 등(2018)이 제안한 방법으로, 두 이미지와 해당 레이블 간의 선형 보간을 통해 새로운 훈련 샘플을 생성합니다. 두 입력 이미지 $x_i$와 $x_j$, 그리고 그들의 레이블 $y_i$와 $y_j$가 주어졌을 때, Mixup은 새로운 이미지 $\tilde{x}$와 레이블 $\tilde{y}$를 다음과 같이 생성합니다:
\begin{equation}
\tilde{x} = \lambda x_i + (1 - \lambda) x_j
\end{equation}
\begin{equation}
\tilde{y} = \lambda y_i + (1 - \lambda) y_j
\end{equation}
여기서 $\lambda$는 Beta 분포 $\text{Beta}(\alpha, \alpha)$에서 샘플링되며, $\alpha$는 하이퍼파라미터입니다. 이 기법은 모델이 훈련 예제 사이에서 선형적으로 동작하도록 유도하여 과적합을 줄이고 일반화 성능을 향상시킵니다.

\subsection{Cutout}
DeVries와 Taylor(2017)가 제안한 Cutout은 훈련 중에 입력 이미지의 사각형 영역을 무작위로 마스킹하는 방법입니다. 이를 통해 모델이 가려지지 않은 부분에 집중하여 더 강인한 특징을 학습할 수 있게 합니다. Cutout 연산은 다음과 같이 정의됩니다:
\begin{equation}
x' = x \odot m
\end{equation}
여기서 $x$는 입력 이미지이고, $m$은 $x$와 동일한 크기의 이진 마스크로, 무작위 사각형 영역이 0으로 설정되어 있으며, $\odot$는 요소별 곱셈을 나타냅니다. 마스크된 영역의 크기는 하이퍼파라미터입니다.

\subsection{Cutmix}
Cutmix는 Yun 등(2019)이 제안한 방법으로, Mixup과 Cutout의 아이디어를 결합한 것입니다. Cutmix에서는 한 이미지에서 직사각형 패치를 잘라내어 다른 이미지에 붙이고, 레이블을 패치의 면적 비율에 따라 혼합합니다. Cutmix 연산은 다음과 같이 정의됩니다:
\begin{equation}
\tilde{x} = M \odot x_i + (1 - M) \odot x_j
\end{equation}
\begin{equation}
\tilde{y} = \lambda y_i + (1 - \lambda) y_j
\end{equation}
여기서 $M$은 패치의 위치를 나타내는 이진 마스크이고, $\lambda$는 Mixup과 유사하게 패치의 면적 비율입니다. 이 방법은 이미지 내 지역 정보를 유지하면서 다양한 훈련 예제를 제공합니다.

\subsection{구현}
이 증강 기법들은 Python과 PyTorch를 사용하여 구현되었습니다. 우리는 다양한 데이터셋을 사용하여 이 기법들이 모델 성능과 강인성에 미치는 영향을 평가하기 위해 광범위한 실험을 수행했습니다. 각 방법의 하이퍼파라미터는 최적의 결과를 얻기 위해 세밀하게 조정되었습니다.
이러한 고급 증강 기술은 널리 채택되었으며 다양한 이미지 분류 작업에서 상당한 개선을 보여주었습니다. 다음 섹션에서는 모델 성능 향상에 있어 Mixup, Cutout 및 Cutmix의 효율성을 보여주는 방법론과 경험적 결과를 자세히 살펴보겠습니다.








%--- Section ---%
\section{Result}\label{sec3}


본 연구에서는 Mixup, Cutmix, Cutout의 세 가지 고급 데이터 증강 기법을 사용합니다. 각각의 방법은 다양한 훈련 샘플을 생성함으로써 합성곱 신경망(CNN)의 강인성과 일반화 능력을 향상시키는 데 중점을 둡니다.



\subsection{4가지 모델 val accuracy}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{5.PNG}
  \caption{훈련과정 피규어}
  \label{fig:label}
\end{figure}

CutMix와 MixUp을 포함한 데이터 증강 방법이 검증 정확도 향상에 가장 효과적입니다. 일반적인 데이터 증강 방법도 No Augmentation보다 성능이 더 좋습니다. 특히, MixUp을 사용한 경우 검증 정확도가 가장 높게 나타나는 경향을 보입니다.



\subsection{4가지 모델 val loss}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{6.PNG}
  \caption{훈련과정 피규어}
  \label{fig:label}
\end{figure}

CutMix를 포함한 데이터 증강 방법이 검증 손실을 가장 효과적으로 줄이는 반면, MixUp을 포함한 방법은 손실 감소 효과가 덜합니다. 일반적인 데이터 증강 방법도 No Augmentation보다 성능이 더 좋습니다.




\subsection{요약}
모델은 Augmentation + CutMix, Augmentation, Augmentation + Mixup, Augmentation 순으로 좋은 것으로 나타났습니다.


\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{resualt.PNG}
  \caption{훈련과정 피규어}
  \label{fig:label}
\end{figure}


일반적인 데이터 증강을 사용하면 검증 손실이 감소하고 검증 정확도가 약간 향상됩니다.
CutMix 기법을 추가로 사용하면 검증 손실은 동일하지만, 검증 정확도가 더 향상됩니다.
Mixup 기법을 추가로 사용하면 검증 손실이 증가하지만, 검증 정확도는 일반 데이터 증강과 동일한 수준을 유지합니다.




%--- Section ---%
\section{Conclusion}\label{sec4}


\subsection{기여 : 향상된 일반화:}
Mixup, Cutmix 및 Cutout에 대한 연구는 이러한 증강 기술이 CNN(컨볼루션 신경망)의 일반화 능력을 어떻게 향상시키는지에 대한 실질적인 증거를 제공합니다. 이러한 방법은 보다 다양한 훈련 샘플을 생성함으로써 모델이 보이지 않는 데이터에서 더 나은 성능을 발휘하는 데 도움이 됩니다.

\subsection{기여 : 작업 전반에 걸친 다양성}
이미지 분류, 객체 감지, 준지도 학습과 같은 다양한 작업에 이러한 방법을 적용할 수 있다는 점은 컴퓨터 비전 분야에서의 다양성과 광범위한 유용성을 강조합니다

\subsection{기여 :실증적 검증}
이 연구에서 제공된 실증적 분석은 이러한 기술의 효과를 뒷받침하며 기계 학습 및 딥 러닝 분야의 향후 연구 및 실제 적용을 위한 벤치마크를 제공합니다



\subsection{한계 : 하이퍼매개변수 감도}
한 가지 주요 제한 사항은 컷아웃 영역의 크기 또는 Mixup의 보간 매개변수와 같은 하이퍼매개변수 선택에 대한 이러한 방법의 민감도입니다. 향후 연구에서는 최적의 성능을 위해 이러한 매개변수를 자동으로 조정하는 적응 메커니즘을 개발하는 데 중점을 둘 수 있습니다.

\subsection{한계 : 계산 오버헤드}
이러한 증강 기술을 구현하면 훈련 중에 계산 오버헤드가 추가될 수 있습니다. 보다 효율적인 구현이나 근사치를 탐색하면 이 문제를 완화할 수 있습니다.

\subsection{한계 : 제한된 적용 가능성}
이러한 방법은 이미지 데이터에 적합하지만 다른 유형의 데이터(예: 텍스트, 오디오)에 대한 적용 가능성은 여전히 제한적입니다. 이러한 기술을 다른 영역으로 확장하는 것은 향후 연구를 위한 귀중한 영역이 될 수 있습니다



%--- Section ---%
\section{연구의 의미와 저자의 기대}\label{sec5}

이 연구는 기계 학습의 중요한 과제, 즉 모델 일반화 및 견고성 향상을 다루기 때문에 중요합니다. Mixup, Cutmix 및 Cutout을 도입하고 검증함으로써 이 연구는 연구자와 실무자가 모델의 성능을 향상시킬 수 있는 실용적인 도구를 제공합니다. 이러한 기술은 과적합 위험을 완화하고, 보이지 않는 다양한 데이터를 효과적으로 처리하는 모델의 능력을 향상시키는 데 도움이 됩니다
\subsection{모범 사례 가이드}
데이터 확대의 모범 사례에 대한 가이드 역할을 하며 향후 작업에서 복제하고 구축할 수 있는 명확한 예와 결과를 제공합니다.
\subsection{추가 연구 촉진}
적응형 및 자동화된 증강 기술에 대한 추가 연구와 새로운 영역 및 응용 분야에서 이러한 방법의 탐색을 장려합니다
\subsection{실용적 구현 개선}
보다 강력하고 일반화 가능한 기계 학습 모델을 개발하여 다양한 산업 및 연구 분야에서 AI 시스템의 실제 구현을 개선합니다



%--- Section ---%
\section{References}\label{sec6}
[1] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz.: [mixup: Beyond Empirical Risk Minimization 2017]
[2] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, Youngjoon Yoo : [CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features 2019]



\end{document}